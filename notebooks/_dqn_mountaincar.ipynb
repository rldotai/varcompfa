{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple DQN for Mountain Car\n",
    "\n",
    "Here is an extremely simple deep-q-network implementation for mountain car.\n",
    "\n",
    "It is far from optimal in a computation sense, and it doesn't make use of the tricks necessary to ensure consistently good performance. \n",
    "In fact, the network can diverge if the exploration causes it to get too far off track.\n",
    "However, it works surprisingly well for a first attempt.\n",
    "In particular, it's interesting to note that adding a bit of depth can cause immediate improvements in the network's ability to solve the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import pinv\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "import mdpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-21 00:51:49,021] Making new env: MountainCar-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = env.observation_space.shape\n",
    "n_inputs = reduce(lambda x, y: x*y, INPUT_SHAPE, 1)\n",
    "n_outputs = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bab/.anaconda3/envs/varcompfa/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# ses = tf.Session()\n",
    "ses = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "X  = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "# R  = tf.placeholder(tf.float32, shape=[None])\n",
    "A  = tf.placeholder(tf.int32, shape=[None])\n",
    "yq = tf.placeholder(tf.float32, shape=[None]) \n",
    "\n",
    "# Parameters\n",
    "gamma = tf.constant(0.9999)\n",
    "\n",
    "\n",
    "# Define network\n",
    "# w_fc1 = tf.truncated_normal()\n",
    "fc1 = tf.contrib.layers.fully_connected(X, 128)\n",
    "fc2 = tf.contrib.layers.fully_connected(fc1, 32)\n",
    "\n",
    "# Network outputs are action-values given input observations\n",
    "out = tf.contrib.layers.fully_connected(fc2, n_outputs, activation_fn=None)\n",
    "\n",
    "# Get q-values\n",
    "action_mask = tf.cast(tf.one_hot(A, n_outputs), tf.bool)\n",
    "q_value = tf.boolean_mask(out, action_mask)\n",
    "\n",
    "# Next q-value with discounting\n",
    "q_greedy = tf.reduce_max(out, 1)\n",
    "q_next = tf.mul(gamma, q_greedy)\n",
    "\n",
    "greedy_action = tf.argmax(out, 1)\n",
    "\n",
    "# Define loss\n",
    "losses = tf.squared_difference(q_value, yq)\n",
    "loss = tf.reduce_mean(losses,)\n",
    "\n",
    "# Define optimizer\n",
    "# optimizer = tf.train.GradientDescentOptimizer(1e-2)\n",
    "# optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "train_op = optimizer.minimize(loss, global_step=tf.contrib.framework.get_global_step())\n",
    "\n",
    "tf.initialize_all_variables().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_x_ = [env.observation_space.sample()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1149, -0.0782,  0.0184]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.eval(feed_dict={X: _x_, A: [2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_value.eval(feed_dict={X: _x_, A: [0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0556], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.run(q_greedy, feed_dict={X: [env.observation_space.sample()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_next.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1707,  0.1707,  0.1707], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.run(q_next, feed_dict={X: [env.observation_space.sample()]*3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0343, -0.0097, -0.0294]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.eval(feed_dict={X: [init_obs]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ses.run(train_op, feed_dict={X: [obs], A: [action], yq: q_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3501.7778], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.run(q_value, feed_dict={X: [obs], A: [action], yq: q_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3511.4417, -3508.9768, -3501.7778]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.run(out, feed_dict={X: [obs], A: [action], yq: q_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3511.4917, -3508.9631, -3501.9343]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.run(out, feed_dict={X: [obs], A: [action], yq: q_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.run(greedy_action, feed_dict={X: [obs], A: [action], yq: q_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3501.584], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses.run(q_next, feed_dict={X: [obs], A: [action], yq: q_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "[[-0.0064  0.054  -0.0544]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 1\n",
      "[[-551.5478 -550.9449 -531.4397]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 2\n",
      "[[-657.6057 -645.6402 -628.7264]]\n",
      "Reached the end in: 1578 steps\n",
      "Episode: 3\n",
      "[[-740.5845 -748.1631 -678.0052]]\n",
      "Reached the end in: 1188 steps\n",
      "Episode: 4\n",
      "[[-754.8339 -767.7115 -699.524 ]]\n",
      "Reached the end in: 978 steps\n",
      "Episode: 5\n",
      "[[-754.6192 -763.8103 -704.7495]]\n",
      "Reached the end in: 851 steps\n",
      "Episode: 6\n",
      "[[-793.7819 -823.4808 -765.5874]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 7\n",
      "[[-821.1561 -836.3354 -809.0098]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 8\n",
      "[[-852.5285 -846.9985 -855.2771]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 9\n",
      "[[-797.4323 -831.5331 -843.3887]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 10\n",
      "[[ -981.5047 -1015.6758 -1009.6324]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 11\n",
      "[[-1085.151  -1024.1689 -1093.1429]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 12\n",
      "[[-1192.9019 -1265.5034 -1253.1075]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 13\n",
      "[[-1365.4994 -1364.6    -1376.4257]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 14\n",
      "[[-1652.7159 -1678.6285 -1678.3196]]\n",
      "Reached the end in: 180 steps\n",
      "Episode: 15\n",
      "[[-1741.5939 -1702.2898 -1644.9575]]\n",
      "Reached the end in: 919 steps\n",
      "Episode: 16\n",
      "[[-1683.6093 -1689.8936 -1536.9628]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 17\n",
      "[[-1677.1381 -1700.6573 -1712.0923]]\n",
      "Reached the end in: 1047 steps\n",
      "Episode: 18\n",
      "[[-1588.1013 -1592.7694 -1417.3556]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 19\n",
      "[[-1325.4769 -1374.3995 -1366.4966]]\n",
      "Reached the end in: 1728 steps\n",
      "Episode: 20\n",
      "[[-1180.6996 -1185.9863 -1117.256 ]]\n",
      "Reached the end in: 1025 steps\n",
      "Episode: 21\n",
      "[[-1138.4065 -1133.9924 -1064.8868]]\n",
      "Reached the end in: 1360 steps\n",
      "Episode: 22\n",
      "[[-1122.899  -1114.5951 -1113.3044]]\n",
      "Reached the end in: 299 steps\n",
      "Episode: 23\n",
      "[[-1195.7633 -1198.0105 -1190.7716]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 24\n",
      "[[-1326.9194 -1368.1019 -1378.8383]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 25\n",
      "[[-1535.2107 -1455.4917 -1549.9397]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 26\n",
      "[[-1945.8734 -1849.2916 -1917.1028]]\n",
      "Reached the end in: 477 steps\n",
      "Episode: 27\n",
      "[[-2074.6292 -2061.4158 -1972.1858]]\n",
      "Reached the end in: 918 steps\n",
      "Episode: 28\n",
      "[[-2105.0378 -2060.7644 -1915.592 ]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 29\n",
      "[[-2074.0522 -1999.5085 -2072.8276]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 30\n",
      "[[-1784.0216 -1795.3486 -1804.1327]]\n",
      "Reached the end in: 332 steps\n",
      "Episode: 31\n",
      "[[-1708.4237 -1703.3568 -1604.0117]]\n",
      "Reached the end in: 1104 steps\n",
      "Episode: 32\n",
      "[[-1704.9089 -1673.6346 -1598.7913]]\n",
      "Reached the end in: 791 steps\n",
      "Episode: 33\n",
      "[[-1598.6587 -1613.954  -1574.5438]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 34\n",
      "[[-1695.0834 -1698.1022 -1715.0098]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 35\n",
      "[[-2257.2412 -2253.7095 -2251.0249]]\n",
      "Reached the end in: 486 steps\n",
      "Episode: 36\n",
      "[[-2491.8691 -2509.5085 -2434.0569]]\n",
      "Reached the end in: 1186 steps\n",
      "Episode: 37\n",
      "[[-2423.2344 -2438.5569 -2310.3679]]\n",
      "Reached the end in: 622 steps\n",
      "Episode: 38\n",
      "[[-2333.6367 -2325.908  -2181.5913]]\n",
      "Reached the end in: 806 steps\n",
      "Episode: 39\n",
      "[[-2222.7683 -2188.1003 -2073.6863]]\n",
      "Reached the end in: 541 steps\n",
      "Episode: 40\n",
      "[[-2000.7567 -1989.7242 -1895.7047]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 41\n",
      "[[-2493.5608 -2431.2478 -2498.1926]]\n",
      "Reached the end in: 1082 steps\n",
      "Episode: 42\n",
      "[[-2984.7739 -2989.6138 -2918.9692]]\n",
      "Reached the end in: 1961 steps\n",
      "Episode: 43\n",
      "[[-3167.0227 -3160.2673 -3089.4333]]\n",
      "Reached the end in: 356 steps\n",
      "Episode: 44\n",
      "[[-3252.6387 -3209.0247 -3199.1763]]\n",
      "Reached the end in: 261 steps\n",
      "Episode: 45\n",
      "[[-3383.7761 -3382.3918 -3353.1345]]\n",
      "Reached the end in: 1875 steps\n",
      "Episode: 46\n",
      "[[-4118.8496 -4133.1074 -4079.2014]]\n",
      "Reached the end in: 486 steps\n",
      "Episode: 47\n",
      "[[-3848.0779 -3839.6843 -3786.9795]]\n",
      "Reached the end in: 880 steps\n",
      "Episode: 48\n",
      "[[-3911.2991 -3925.1714 -3789.845 ]]\n",
      "Reached the end in: 596 steps\n",
      "Episode: 49\n",
      "[[-3712.4524 -3692.301  -3774.3269]]\n",
      "Reached the end in: 1956 steps\n",
      "Episode: 50\n",
      "[[-4053.8003 -4049.0217 -3853.9277]]\n",
      "Reached the end in: 816 steps\n",
      "Episode: 51\n",
      "[[-3836.3879 -3852.177  -3741.5974]]\n",
      "Reached the end in: 538 steps\n",
      "Episode: 52\n",
      "[[-3705.7927 -3684.573  -3616.9238]]\n",
      "Reached the end in: 1380 steps\n",
      "Episode: 53\n",
      "[[-3835.7075 -3857.4902 -3664.7021]]\n",
      "Reached the end in: 515 steps\n",
      "Episode: 54\n",
      "[[-3350.3601 -3368.3682 -3240.7478]]\n",
      "Reached the end in: 1459 steps\n",
      "Episode: 55\n",
      "[[-3214.6621 -3209.4771 -3092.23  ]]\n",
      "Reached the end in: 1490 steps\n",
      "Episode: 56\n",
      "[[-3446.9285 -3457.4233 -3393.4031]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 57\n",
      "[[-3800.7524 -3794.8374 -3838.1033]]\n",
      "Reached the end in: 326 steps\n",
      "Episode: 58\n",
      "[[-3771.3103 -3788.3696 -3669.6169]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 59\n",
      "[[-4142.9771 -4123.2417 -4183.5015]]\n",
      "Reached the end in: 1291 steps\n",
      "Episode: 60\n",
      "[[-4377.3022 -4378.0596 -4182.3105]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 61\n",
      "[[-4732.1631 -4733.3457 -4744.3462]]\n",
      "Reached the end in: 573 steps\n",
      "Episode: 62\n",
      "[[-4513.7935 -4520.5288 -4261.6201]]\n",
      "Reached the end in: 1006 steps\n",
      "Episode: 63\n",
      "[[-4084.887  -4092.4907 -3947.2834]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 64\n",
      "[[-4583.5376 -4584.8052 -4586.4756]]\n",
      "Reached the end in: 686 steps\n",
      "Episode: 65\n",
      "[[-4238.356  -4234.5859 -3913.3416]]\n",
      "Reached the end in: 1081 steps\n",
      "Episode: 66\n",
      "[[-3873.2136 -3905.1792 -3666.5757]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 67\n",
      "[[-3889.0803 -3823.1956 -3894.1682]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 68\n",
      "[[-4207.4414 -4233.8389 -4227.5703]]\n",
      "Reached the end in: 1396 steps\n",
      "Episode: 69\n",
      "[[-4094.9932 -4102.9966 -3881.603 ]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 70\n",
      "[[-3958.8787 -3958.1599 -3992.8225]]\n",
      "Reached the end in: 791 steps\n",
      "Episode: 71\n",
      "[[-3814.0938 -3807.8293 -3613.6865]]\n",
      "Reached the end in: 1344 steps\n",
      "Episode: 72\n",
      "[[-3573.5676 -3579.6311 -3475.4502]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 73\n",
      "[[-4312.1758 -4317.8823 -4034.7949]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 74\n",
      "[[-4497.4194 -4499.3389 -4490.582 ]]\n",
      "Reached the end in: 581 steps\n",
      "Episode: 75\n",
      "[[-4008.8652 -4086.6465 -3644.9451]]\n",
      "Reached the end in: 1051 steps\n",
      "Episode: 76\n",
      "[[-3123.2427 -3119.3069 -2993.8186]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 77\n",
      "[[-3566.1282 -3486.0444 -3568.6343]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 78\n",
      "[[-3579.7666 -3581.0544 -3581.8354]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 79\n",
      "[[-3943.1802 -3883.3801 -3951.9084]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 80\n",
      "[[-4171.0112 -4161.0112 -4151.811 ]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 81\n",
      "[[-3950.8555 -3819.8906 -3949.1531]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 82\n",
      "[[-4134.8613 -4175.9668 -4190.0884]]\n",
      "Reached the end in: 549 steps\n",
      "Episode: 83\n",
      "[[-3931.0667 -3955.8545 -3665.6672]]\n",
      "Reached the end in: 1461 steps\n",
      "Episode: 84\n",
      "[[-3385.2104 -3370.592  -3110.6975]]\n",
      "Reached the end in: 772 steps\n",
      "Episode: 85\n",
      "[[-2792.5847 -2752.0955 -2653.073 ]]\n",
      "Reached the end in: 649 steps\n",
      "Episode: 86\n",
      "[[-2683.0098 -2678.9827 -2582.8574]]\n",
      "Reached the end in: 534 steps\n",
      "Episode: 87\n",
      "[[-2619.0549 -2619.8074 -2513.1992]]\n",
      "Reached the end in: 621 steps\n",
      "Episode: 88\n",
      "[[-2740.5991 -2724.4312 -2621.9539]]\n",
      "Reached the end in: 1269 steps\n",
      "Episode: 89\n",
      "[[-3249.481  -3279.2449 -3078.4104]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 90\n",
      "[[-4086.135  -4086.2725 -4080.2495]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 91\n",
      "[[-4320.8706 -4341.5767 -4441.9893]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 92\n",
      "[[-4711.2007 -4765.0771 -4746.6621]]\n",
      "Reached the end in: 1815 steps\n",
      "Episode: 93\n",
      "[[-4838.8774 -4844.1499 -4612.9277]]\n",
      "Reached the end in: 1816 steps\n",
      "Episode: 94\n",
      "[[-4384.6768 -4395.0708 -4084.9587]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 95\n",
      "[[-4104.0679 -4118.7446 -4137.0156]]\n",
      "Failed to reach the end within the time limit!\n",
      "Episode: 96\n",
      "[[-4290.7334 -4236.5791 -4301.5649]]\n",
      "Reached the end in: 1618 steps\n",
      "Episode: 97\n",
      "[[-4089.6279 -4110.3286 -3862.6848]]\n",
      "Reached the end in: 806 steps\n",
      "Episode: 98\n",
      "[[-3462.4592 -3446.9111 -3347.2214]]\n",
      "Reached the end in: 1833 steps\n",
      "Episode: 99\n",
      "[[-3516.8694 -3516.864  -3302.3391]]\n",
      "Failed to reach the end within the time limit!\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "max_steps = 2000\n",
    "\n",
    "\n",
    "epsilon = 2e-2\n",
    "\n",
    "xlst = []\n",
    "dlst = []\n",
    "for i in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    print(\"Episode: %d\"%i)\n",
    "    print(out.eval(feed_dict={X: [init_obs]}))\n",
    "    for j in range(max_steps):\n",
    "        if np.random.random() <= epsilon:\n",
    "            action = np.random.randint(n_outputs)\n",
    "        else:\n",
    "            action = int(ses.run(greedy_action, feed_dict={X: [obs]}))\n",
    "            \n",
    "        # Take action\n",
    "        obs_p, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Q-value update\n",
    "        q_curr = ses.run(q_value, feed_dict={X: [obs], A: [action]})\n",
    "        q_pred = reward + ses.run(q_next, feed_dict={X: [obs_p]})\n",
    "        \n",
    "        # Record information\n",
    "        delta = float(q_pred - q_curr)\n",
    "        dlst.append(delta)\n",
    "        xlst.append(obs)\n",
    "        \n",
    "        ses.run(train_op, feed_dict={X: [obs], A: [action], yq: q_pred})\n",
    "        # Break if done\n",
    "        if done:\n",
    "            print(\"Reached the end in: %d steps\"%j)\n",
    "            break\n",
    "        \n",
    "        # Set up for next iteration\n",
    "        obs = obs_p\n",
    "    else:\n",
    "        print(\"Failed to reach the end within the time limit!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8926.7139, -8911.9717, -8893.293 ]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.eval(feed_dict={X: [init_obs]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:varcompfa]",
   "language": "python",
   "name": "conda-env-varcompfa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
